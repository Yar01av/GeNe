{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 12:11:54,565\tWARNING function_runner.py:563 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n",
      "2022-07-28 12:11:54,576\tWARNING bayesopt.py:397 -- BayesOpt does not support specific sampling methods. The Uniform sampler will be dropped.\n",
      "2022-07-28 12:11:54,623\tWARNING tune.py:574 -- Tune detects GPUs, but no trials are using GPUs. To enable trials to use GPUs, set tune.run(resources_per_trial={'gpu': 1}...) which allows Tune to expose 1 GPU to each trial. You can also override `Trainable.default_resource_request` if using the Trainable API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[1m\u001B[36m(scheduler +4m32s)\u001B[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
      "\u001B[2m\u001B[1m\u001B[33m(scheduler +4m32s)\u001B[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 12:16:26,876\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 7.497086866493021}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[1m\u001B[33m(scheduler +6m12s)\u001B[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 12:18:08,180\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 7.497092572217386}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[1m\u001B[33m(scheduler +8m2s)\u001B[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 12:21:30,978\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 7.497058604845378}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[1m\u001B[33m(scheduler +11m23s)\u001B[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 12:23:55,917\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 7.497071314823949}.\n",
      "2022-07-28 12:24:55,210\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 3.1258487904983068}.\n",
      "2022-07-28 12:25:07,604\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 9.151080150752222}.\n",
      "2022-07-28 12:26:05,922\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 3.1284569602747028}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[1m\u001B[33m(scheduler +15m23s)\u001B[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001B[2m\u001B[1m\u001B[33m(scheduler +16m3s)\u001B[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001B[2m\u001B[1m\u001B[33m(scheduler +17m3s)\u001B[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 12:29:03,717\tWARNING worker.py:1228 -- The actor or task with ID ffffffffffffffff948da94512724b279ec08d4001000000 cannot be scheduled right now. You can ignore this message if this Ray cluster is expected to auto-scale or if you specified a runtime_env for this actor or task, which may take time to install.  Otherwise, this is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increasing the resources available to this Ray cluster.\n",
      "Required resources for this actor or task: {CPU_group_9314cf313ee849eee261af01f813bf07: 1.000000}, {CPU_group_0_9314cf313ee849eee261af01f813bf07: 1.000000}\n",
      "Available resources on this node: {0.000000/8.000000 CPU, 685210800.000000 GiB/685210800.000000 GiB memory, 1.000000/1.000000 GPU, 342605400.000000 GiB/342605400.000000 GiB object_store_memory, 1000.000000/1000.000000 bundle_group_0_f9dca0b445ccb3ad579394fd1725599f, 1000.000000/1000.000000 bundle_group_f9dca0b445ccb3ad579394fd1725599f, 0.000000/1.000000 CPU_group_0_3d3989093fd2b81949bf275bacdeae27, 1000.000000/1000.000000 bundle_group_cc77f99c1003874f12eca6d36687f875, 1000.000000/1000.000000 bundle_group_0_43cc40ec9ba15002ba5f68b82681da26, 1.000000/1.000000 node:217.105.36.71, 1000.000000/1000.000000 bundle_group_0_3d3989093fd2b81949bf275bacdeae27, 1000.000000/1000.000000 bundle_group_a8479b2e736afefd9496e1f3f05dc591, 1000.000000/1000.000000 bundle_group_0_6422cea42a8322ad250a2009171bb654, 1000.000000/1000.000000 bundle_group_0_a8479b2e736afefd9496e1f3f05dc591, 0.000000/1.000000 CPU_group_0_5f703ff02b0ec3565631e0ea903024f5, 1000.000000/1000.000000 bundle_group_43cc40ec9ba15002ba5f68b82681da26, 0.000000/1.000000 CPU_group_9314cf313ee849eee261af01f813bf07, 0.000000/1.000000 CPU_group_0_6422cea42a8322ad250a2009171bb654, 1000.000000/1000.000000 bundle_group_3d3989093fd2b81949bf275bacdeae27, 1000.000000/1000.000000 bundle_group_5f703ff02b0ec3565631e0ea903024f5, 1000.000000/1000.000000 bundle_group_6422cea42a8322ad250a2009171bb654, 0.000000/1.000000 CPU_group_f9dca0b445ccb3ad579394fd1725599f, 0.000000/1.000000 CPU_group_43cc40ec9ba15002ba5f68b82681da26, 1000.000000/1000.000000 bundle_group_9314cf313ee849eee261af01f813bf07, 0.000000/1.000000 CPU_group_5f703ff02b0ec3565631e0ea903024f5, 0.000000/1.000000 CPU_group_6422cea42a8322ad250a2009171bb654, 0.000000/1.000000 CPU_group_0_43cc40ec9ba15002ba5f68b82681da26, 1.000000/1.000000 accelerator_type:G, 1000.000000/1000.000000 bundle_group_0_cc77f99c1003874f12eca6d36687f875, 0.000000/1.000000 CPU_group_3d3989093fd2b81949bf275bacdeae27, 0.000000/1.000000 CPU_group_0_cc77f99c1003874f12eca6d36687f875, 0.000000/1.000000 CPU_group_0_f9dca0b445ccb3ad579394fd1725599f, 0.000000/1.000000 CPU_group_0_a8479b2e736afefd9496e1f3f05dc591, 1000.000000/1000.000000 bundle_group_0_9314cf313ee849eee261af01f813bf07, 0.000000/1.000000 CPU_group_a8479b2e736afefd9496e1f3f05dc591, 1000.000000/1000.000000 bundle_group_0_5f703ff02b0ec3565631e0ea903024f5, 0.000000/1.000000 CPU_group_cc77f99c1003874f12eca6d36687f875, 0.000000/1.000000 CPU_group_0_9314cf313ee849eee261af01f813bf07}\n",
      "In total there are 0 pending tasks and 1 pending actors on this node.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(ImplicitFunc pid=22552)\u001B[0m \n",
      "\u001B[2m\u001B[1m\u001B[33m(scheduler +19m23s)\u001B[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 12:31:53,761\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 1.1556380838883624}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[1m\u001B[33m(scheduler +20m3s)\u001B[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 12:33:25,497\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 9.151084254150309}.\n",
      "2022-07-28 12:33:30,123\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 1.1556415604708943}.\n",
      "2022-07-28 12:33:49,851\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 3.128485163739201}.\n",
      "2022-07-28 12:34:46,193\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 7.497061797179595}.\n",
      "2022-07-28 12:35:55,407\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 1.155636578873165}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[1m\u001B[33m(scheduler +26m44s)\u001B[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 12:38:43,931\tWARNING worker.py:1228 -- The actor or task with ID ffffffffffffffff1f8bf47db0f3e1176a73cab001000000 cannot be scheduled right now. You can ignore this message if this Ray cluster is expected to auto-scale or if you specified a runtime_env for this actor or task, which may take time to install.  Otherwise, this is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increasing the resources available to this Ray cluster.\n",
      "Required resources for this actor or task: {CPU_group_0_43cc40ec9ba15002ba5f68b82681da26: 1.000000}, {CPU_group_43cc40ec9ba15002ba5f68b82681da26: 1.000000}\n",
      "Available resources on this node: {0.000000/8.000000 CPU, 685210800.000000 GiB/685210800.000000 GiB memory, 1.000000/1.000000 GPU, 342605400.000000 GiB/342605400.000000 GiB object_store_memory, 1000.000000/1000.000000 bundle_group_0_f9dca0b445ccb3ad579394fd1725599f, 1000.000000/1000.000000 bundle_group_f9dca0b445ccb3ad579394fd1725599f, 0.000000/1.000000 CPU_group_0_3d3989093fd2b81949bf275bacdeae27, 1000.000000/1000.000000 bundle_group_cc77f99c1003874f12eca6d36687f875, 1000.000000/1000.000000 bundle_group_0_43cc40ec9ba15002ba5f68b82681da26, 1.000000/1.000000 node:217.105.36.71, 1000.000000/1000.000000 bundle_group_0_3d3989093fd2b81949bf275bacdeae27, 1000.000000/1000.000000 bundle_group_a8479b2e736afefd9496e1f3f05dc591, 1000.000000/1000.000000 bundle_group_0_6422cea42a8322ad250a2009171bb654, 1000.000000/1000.000000 bundle_group_0_a8479b2e736afefd9496e1f3f05dc591, 0.000000/1.000000 CPU_group_0_5f703ff02b0ec3565631e0ea903024f5, 1000.000000/1000.000000 bundle_group_43cc40ec9ba15002ba5f68b82681da26, 0.000000/1.000000 CPU_group_9314cf313ee849eee261af01f813bf07, 0.000000/1.000000 CPU_group_0_6422cea42a8322ad250a2009171bb654, 1000.000000/1000.000000 bundle_group_3d3989093fd2b81949bf275bacdeae27, 1000.000000/1000.000000 bundle_group_5f703ff02b0ec3565631e0ea903024f5, 1000.000000/1000.000000 bundle_group_6422cea42a8322ad250a2009171bb654, 0.000000/1.000000 CPU_group_f9dca0b445ccb3ad579394fd1725599f, 0.000000/1.000000 CPU_group_43cc40ec9ba15002ba5f68b82681da26, 1000.000000/1000.000000 bundle_group_9314cf313ee849eee261af01f813bf07, 0.000000/1.000000 CPU_group_5f703ff02b0ec3565631e0ea903024f5, 0.000000/1.000000 CPU_group_6422cea42a8322ad250a2009171bb654, 0.000000/1.000000 CPU_group_0_43cc40ec9ba15002ba5f68b82681da26, 1.000000/1.000000 accelerator_type:G, 1000.000000/1000.000000 bundle_group_0_cc77f99c1003874f12eca6d36687f875, 0.000000/1.000000 CPU_group_3d3989093fd2b81949bf275bacdeae27, 0.000000/1.000000 CPU_group_0_cc77f99c1003874f12eca6d36687f875, 0.000000/1.000000 CPU_group_0_f9dca0b445ccb3ad579394fd1725599f, 0.000000/1.000000 CPU_group_0_a8479b2e736afefd9496e1f3f05dc591, 1000.000000/1000.000000 bundle_group_0_9314cf313ee849eee261af01f813bf07, 0.000000/1.000000 CPU_group_a8479b2e736afefd9496e1f3f05dc591, 1000.000000/1000.000000 bundle_group_0_5f703ff02b0ec3565631e0ea903024f5, 0.000000/1.000000 CPU_group_cc77f99c1003874f12eca6d36687f875, 0.000000/1.000000 CPU_group_0_9314cf313ee849eee261af01f813bf07}\n",
      "In total there are 0 pending tasks and 1 pending actors on this node.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[1m\u001B[33m(scheduler +27m44s)\u001B[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001B[2m\u001B[1m\u001B[33m(scheduler +29m34s)\u001B[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 12:41:46,801\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 5.591877897280385}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[1m\u001B[33m(scheduler +30m35s)\u001B[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 12:42:33,771\tWARNING worker.py:1228 -- The actor or task with ID ffffffffffffffffe8391c3ad9ef62c3e775bee101000000 cannot be scheduled right now. You can ignore this message if this Ray cluster is expected to auto-scale or if you specified a runtime_env for this actor or task, which may take time to install.  Otherwise, this is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increasing the resources available to this Ray cluster.\n",
      "Required resources for this actor or task: {CPU_group_0_5f703ff02b0ec3565631e0ea903024f5: 1.000000}, {CPU_group_5f703ff02b0ec3565631e0ea903024f5: 1.000000}\n",
      "Available resources on this node: {0.000000/8.000000 CPU, 685210800.000000 GiB/685210800.000000 GiB memory, 1.000000/1.000000 GPU, 342605400.000000 GiB/342605400.000000 GiB object_store_memory, 1000.000000/1000.000000 bundle_group_0_f9dca0b445ccb3ad579394fd1725599f, 1000.000000/1000.000000 bundle_group_f9dca0b445ccb3ad579394fd1725599f, 0.000000/1.000000 CPU_group_0_3d3989093fd2b81949bf275bacdeae27, 1000.000000/1000.000000 bundle_group_cc77f99c1003874f12eca6d36687f875, 1000.000000/1000.000000 bundle_group_0_43cc40ec9ba15002ba5f68b82681da26, 1.000000/1.000000 node:217.105.36.71, 1000.000000/1000.000000 bundle_group_0_3d3989093fd2b81949bf275bacdeae27, 1000.000000/1000.000000 bundle_group_a8479b2e736afefd9496e1f3f05dc591, 1000.000000/1000.000000 bundle_group_0_6422cea42a8322ad250a2009171bb654, 1000.000000/1000.000000 bundle_group_0_a8479b2e736afefd9496e1f3f05dc591, 0.000000/1.000000 CPU_group_0_5f703ff02b0ec3565631e0ea903024f5, 1000.000000/1000.000000 bundle_group_43cc40ec9ba15002ba5f68b82681da26, 0.000000/1.000000 CPU_group_9314cf313ee849eee261af01f813bf07, 0.000000/1.000000 CPU_group_0_6422cea42a8322ad250a2009171bb654, 1000.000000/1000.000000 bundle_group_3d3989093fd2b81949bf275bacdeae27, 1000.000000/1000.000000 bundle_group_5f703ff02b0ec3565631e0ea903024f5, 1000.000000/1000.000000 bundle_group_6422cea42a8322ad250a2009171bb654, 0.000000/1.000000 CPU_group_f9dca0b445ccb3ad579394fd1725599f, 0.000000/1.000000 CPU_group_43cc40ec9ba15002ba5f68b82681da26, 1000.000000/1000.000000 bundle_group_9314cf313ee849eee261af01f813bf07, 0.000000/1.000000 CPU_group_5f703ff02b0ec3565631e0ea903024f5, 0.000000/1.000000 CPU_group_6422cea42a8322ad250a2009171bb654, 0.000000/1.000000 CPU_group_0_43cc40ec9ba15002ba5f68b82681da26, 1.000000/1.000000 accelerator_type:G, 1000.000000/1000.000000 bundle_group_0_cc77f99c1003874f12eca6d36687f875, 0.000000/1.000000 CPU_group_3d3989093fd2b81949bf275bacdeae27, 0.000000/1.000000 CPU_group_0_cc77f99c1003874f12eca6d36687f875, 0.000000/1.000000 CPU_group_0_f9dca0b445ccb3ad579394fd1725599f, 0.000000/1.000000 CPU_group_0_a8479b2e736afefd9496e1f3f05dc591, 1000.000000/1000.000000 bundle_group_0_9314cf313ee849eee261af01f813bf07, 0.000000/1.000000 CPU_group_a8479b2e736afefd9496e1f3f05dc591, 1000.000000/1000.000000 bundle_group_0_5f703ff02b0ec3565631e0ea903024f5, 0.000000/1.000000 CPU_group_cc77f99c1003874f12eca6d36687f875, 0.000000/1.000000 CPU_group_0_9314cf313ee849eee261af01f813bf07}\n",
      "In total there are 0 pending tasks and 1 pending actors on this node.\n",
      "2022-07-28 12:47:35,750\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 1.155525329222163}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[1m\u001B[33m(scheduler +35m55s)\u001B[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 12:49:05,582\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 5.591874201070194}.\n",
      "2022-07-28 12:49:30,988\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 17.49060635737066}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[1m\u001B[33m(scheduler +37m55s)\u001B[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001B[2m\u001B[1m\u001B[33m(scheduler +39m5s)\u001B[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 12:52:21,084\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 0.13733483375128402}.\n",
      "2022-07-28 12:53:06,633\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 3.409964561133444}.\n",
      "2022-07-28 12:55:21,021\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 3.128479352440767}.\n",
      "2022-07-28 12:55:35,119\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 1.1556201997567823}.\n",
      "2022-07-28 12:55:36,600\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 1.1556810243697377}.\n",
      "2022-07-28 12:56:21,636\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 18.047264612978378}.\n",
      "2022-07-28 12:56:35,519\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 18.48690102070003}.\n",
      "2022-07-28 12:56:58,217\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 5.5918811355019}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[1m\u001B[33m(scheduler +45m6s)\u001B[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001B[2m\u001B[1m\u001B[33m(scheduler +47m56s)\u001B[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001B[2m\u001B[1m\u001B[33m(scheduler +48m31s)\u001B[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 13:01:32,649\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 0.1373319214251074}.\n",
      "2022-07-28 13:01:38,680\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 9.151061151098407}.\n",
      "2022-07-28 13:02:36,492\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 5.331647268557103}.\n",
      "2022-07-28 13:03:46,453\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 18.487024643954115}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[1m\u001B[33m(scheduler +53m42s)\u001B[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 13:06:09,982\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 1.155619398220654}.\n",
      "2022-07-28 13:06:39,533\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 3.4101057745683034}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[1m\u001B[33m(scheduler +55m52s)\u001B[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 13:07:53,849\tWARNING worker.py:1228 -- The actor or task with ID ffffffffffffffff78fed60ac408e395620cc57101000000 cannot be scheduled right now. You can ignore this message if this Ray cluster is expected to auto-scale or if you specified a runtime_env for this actor or task, which may take time to install.  Otherwise, this is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increasing the resources available to this Ray cluster.\n",
      "Required resources for this actor or task: {CPU_group_3fbb0565a05b41aac0951f1ffdbaf0ab: 1.000000}, {CPU_group_0_3fbb0565a05b41aac0951f1ffdbaf0ab: 1.000000}\n",
      "Available resources on this node: {0.000000/8.000000 CPU, 685210800.000000 GiB/685210800.000000 GiB memory, 1.000000/1.000000 GPU, 342605400.000000 GiB/342605400.000000 GiB object_store_memory, 1000.000000/1000.000000 bundle_group_0_05912330f7f004bb74ef448e415d4505, 0.000000/1.000000 CPU_group_0_3fbb0565a05b41aac0951f1ffdbaf0ab, 0.000000/1.000000 CPU_group_0_3d3989093fd2b81949bf275bacdeae27, 1000.000000/1000.000000 bundle_group_cc77f99c1003874f12eca6d36687f875, 1.000000/1.000000 node:217.105.36.71, 1000.000000/1000.000000 bundle_group_0_3d3989093fd2b81949bf275bacdeae27, 1000.000000/1000.000000 bundle_group_a8479b2e736afefd9496e1f3f05dc591, 1000.000000/1000.000000 bundle_group_0_6422cea42a8322ad250a2009171bb654, 0.000000/1.000000 CPU_group_0_05912330f7f004bb74ef448e415d4505, 1000.000000/1000.000000 bundle_group_0_a8479b2e736afefd9496e1f3f05dc591, 0.000000/1.000000 CPU_group_0_5f703ff02b0ec3565631e0ea903024f5, 0.000000/1.000000 CPU_group_05912330f7f004bb74ef448e415d4505, 0.000000/1.000000 CPU_group_3fbb0565a05b41aac0951f1ffdbaf0ab, 0.000000/1.000000 CPU_group_9314cf313ee849eee261af01f813bf07, 0.000000/1.000000 CPU_group_0_6422cea42a8322ad250a2009171bb654, 1000.000000/1000.000000 bundle_group_05912330f7f004bb74ef448e415d4505, 1000.000000/1000.000000 bundle_group_3fbb0565a05b41aac0951f1ffdbaf0ab, 1000.000000/1000.000000 bundle_group_3d3989093fd2b81949bf275bacdeae27, 1000.000000/1000.000000 bundle_group_5f703ff02b0ec3565631e0ea903024f5, 1000.000000/1000.000000 bundle_group_6422cea42a8322ad250a2009171bb654, 1000.000000/1000.000000 bundle_group_9314cf313ee849eee261af01f813bf07, 0.000000/1.000000 CPU_group_5f703ff02b0ec3565631e0ea903024f5, 0.000000/1.000000 CPU_group_6422cea42a8322ad250a2009171bb654, 1.000000/1.000000 accelerator_type:G, 1000.000000/1000.000000 bundle_group_0_cc77f99c1003874f12eca6d36687f875, 0.000000/1.000000 CPU_group_3d3989093fd2b81949bf275bacdeae27, 0.000000/1.000000 CPU_group_0_cc77f99c1003874f12eca6d36687f875, 1000.000000/1000.000000 bundle_group_0_3fbb0565a05b41aac0951f1ffdbaf0ab, 0.000000/1.000000 CPU_group_0_a8479b2e736afefd9496e1f3f05dc591, 1000.000000/1000.000000 bundle_group_0_9314cf313ee849eee261af01f813bf07, 0.000000/1.000000 CPU_group_a8479b2e736afefd9496e1f3f05dc591, 1000.000000/1000.000000 bundle_group_0_5f703ff02b0ec3565631e0ea903024f5, 0.000000/1.000000 CPU_group_cc77f99c1003874f12eca6d36687f875, 0.000000/1.000000 CPU_group_0_9314cf313ee849eee261af01f813bf07}\n",
      "In total there are 0 pending tasks and 1 pending actors on this node.\n",
      "2022-07-28 13:09:19,518\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 4.6768476936365335}.\n",
      "2022-07-28 13:09:48,421\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 13.754106580210465}.\n",
      "2022-07-28 13:10:45,684\tINFO bayesopt.py:271 -- Skipping duplicated config: {'init_std': 3.5863303435450007}.\n",
      "2022-07-28 13:11:54,779\tINFO stopper.py:344 -- Reached timeout of 3600 seconds. Stopping all trials.\n"
     ]
    }
   ],
   "source": [
    "from gene.optimisers.crossing import CrossingOptimiser\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ray\n",
    "import torch\n",
    "from ray import tune\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "from tqdm import tqdm\n",
    "from ray.tune.suggest.bayesopt import BayesOptSearch\n",
    "\n",
    "from gene.optimisers.annealed_crossing import AnnealedCrossingOptimiser\n",
    "from gene.targets import get_negative_accuracy_target\n",
    "from gene.util import get_accuracy\n",
    "\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "DEVICE = [\"cpu\", \"cuda\"][0]\n",
    "N_EPOCHS = 5\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root=\"./cache\",\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"./cache\",\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "train_data = ray.put(train_data)\n",
    "test_data = ray.put(test_data)\n",
    "\n",
    "\n",
    "def train(config):\n",
    "    # Define the model\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Flatten(),\n",
    "        torch.nn.Linear(28 * 28, 256),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(256, 64),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(64, 10)\n",
    "    )\n",
    "    models = [model.to(DEVICE)]\n",
    "\n",
    "    # Define the optimiser\n",
    "    optimiser = CrossingOptimiser(target_func=get_negative_accuracy_target,\n",
    "                                  random_function=lambda shape: torch.normal(0, config[\"init_std\"], shape),\n",
    "                                  selection_limit=10,\n",
    "                                  max_couples=10,\n",
    "                                  n_children_per_couple=2,\n",
    "                                  device=DEVICE)\n",
    "\n",
    "    # Define the data loaders\n",
    "    train_loader = DataLoader(ray.get(train_data), batch_size=1024, shuffle=True)\n",
    "    test_loader = DataLoader(ray.get(test_data), batch_size=1024)\n",
    "\n",
    "    for e in range(N_EPOCHS):\n",
    "        for images, labels in train_loader:\n",
    "            models = optimiser.step(models, images.to(DEVICE), labels.to(DEVICE))\n",
    "\n",
    "        tune.report(np.mean([get_accuracy(test_loader, m, DEVICE) for m in models]))\n",
    "\n",
    "\n",
    "parameters = {\"init_std\": tune.uniform(0.01, 20)}\n",
    "search_alg = BayesOptSearch(metric=\"_metric\", mode=\"max\")\n",
    "analysis = tune.run(\n",
    "    train,\n",
    "    search_alg=search_alg,\n",
    "    scheduler=ASHAScheduler(metric=\"_metric\", mode=\"max\"),\n",
    "    config=parameters,\n",
    "    time_budget_s=3600,\n",
    "    num_samples=-1,\n",
    "    verbose=0\n",
    "#     resources_per_trial={'gpu': 1},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yaroslav/miniconda3/envs/synapse/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py:565: UserWarning: Dataframes will use '/' instead of '.' to delimit nested result keys in future versions of Ray. For forward compatibility, set the environment variable TUNE_RESULT_DELIM='/'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "          _metric  time_this_iter_s  done  timesteps_total  episodes_total  \\\ntrial_id                                                                     \nb4cbf1a6  0.53475         21.844446  True              NaN             NaN   \nb4ebbf68  0.27135         33.228054  True              NaN             NaN   \nb500773c  0.41193         21.958321  True              NaN             NaN   \nb515478e  0.24309         34.450798  True              NaN             NaN   \nb530b35c  0.49560         21.790014  True              NaN             NaN   \n...           ...               ...   ...              ...             ...   \n0365c884      NaN               NaN   NaN              NaN             NaN   \n0ab8c5be      NaN               NaN   NaN              NaN             NaN   \n0d6b24b4      NaN               NaN   NaN              NaN             NaN   \n12074250      NaN               NaN   NaN              NaN             NaN   \n155f4f6a      NaN               NaN   NaN              NaN             NaN   \n\n          training_iteration                     experiment_id  \\\ntrial_id                                                         \nb4cbf1a6                 5.0  dbcfb69484774346bc4230125d7b9053   \nb4ebbf68                 1.0  738ff7723b8a4ffea3966a4d1a3aefb2   \nb500773c                 5.0  a6033c902bfd4e7c973a3daf12877b67   \nb515478e                 1.0  7db7aedf045045a9881286439d3fe2a7   \nb530b35c                 5.0  7afcfd67ed6841318941af1173e5194f   \n...                      ...                               ...   \n0365c884                 NaN  1aca9fc1aee74e21aaee3b8ed30a635f   \n0ab8c5be                 NaN  9f62ef6ce760445d85e5d6e3710d196a   \n0d6b24b4                 NaN  9b830b62dc354d3fa50b0e2666f1b8b9   \n12074250                 NaN  8c387cd02a244f5687474d4dc06c11aa   \n155f4f6a                 NaN                               NaN   \n\n                         date     timestamp  time_total_s      pid  \\\ntrial_id                                                             \nb4cbf1a6  2022-07-28_12-14-07  1.659003e+09    131.225310  18433.0   \nb4ebbf68  2022-07-28_12-12-29  1.659003e+09     33.228054  18431.0   \nb500773c  2022-07-28_12-14-06  1.659003e+09    129.855627  18428.0   \nb515478e  2022-07-28_12-12-31  1.659003e+09     34.450798  18434.0   \nb530b35c  2022-07-28_12-14-08  1.659003e+09    131.416916  18429.0   \n...                       ...           ...           ...      ...   \n0365c884  2022-07-28_13-11-37  1.659007e+09           NaN  32091.0   \n0ab8c5be  2022-07-28_13-11-41  1.659007e+09           NaN  32116.0   \n0d6b24b4  2022-07-28_13-11-49  1.659007e+09           NaN  32141.0   \n12074250  2022-07-28_13-11-54  1.659007e+09           NaN  32193.0   \n155f4f6a                  NaN           NaN           NaN      NaN   \n\n                             hostname        node_ip  time_since_restore  \\\ntrial_id                                                                   \nb4cbf1a6  yaroslav-B365-M-AORUS-ELITE  217.105.36.71          131.225310   \nb4ebbf68  yaroslav-B365-M-AORUS-ELITE  217.105.36.71           33.228054   \nb500773c  yaroslav-B365-M-AORUS-ELITE  217.105.36.71          129.855627   \nb515478e  yaroslav-B365-M-AORUS-ELITE  217.105.36.71           34.450798   \nb530b35c  yaroslav-B365-M-AORUS-ELITE  217.105.36.71          131.416916   \n...                               ...            ...                 ...   \n0365c884  yaroslav-B365-M-AORUS-ELITE  217.105.36.71                 NaN   \n0ab8c5be  yaroslav-B365-M-AORUS-ELITE  217.105.36.71                 NaN   \n0d6b24b4  yaroslav-B365-M-AORUS-ELITE  217.105.36.71                 NaN   \n12074250  yaroslav-B365-M-AORUS-ELITE  217.105.36.71                 NaN   \n155f4f6a                          NaN            NaN                 NaN   \n\n          timesteps_since_restore  iterations_since_restore  \\\ntrial_id                                                      \nb4cbf1a6                      0.0                       5.0   \nb4ebbf68                      0.0                       1.0   \nb500773c                      0.0                       5.0   \nb515478e                      0.0                       1.0   \nb530b35c                      0.0                       5.0   \n...                           ...                       ...   \n0365c884                      NaN                       NaN   \n0ab8c5be                      NaN                       NaN   \n0d6b24b4                      NaN                       NaN   \n12074250                      NaN                       NaN   \n155f4f6a                      NaN                       NaN   \n\n             experiment_tag  config.init_std  \ntrial_id                                      \nb4cbf1a6  1_init_std=7.4971         7.497057  \nb4ebbf68  2_init_std=19.015        19.014779  \nb500773c  3_init_std=14.643        14.642559  \nb515478e  4_init_std=11.977        11.977183  \nb530b35c  5_init_std=3.1288         3.128813  \n...                     ...              ...  \n0365c884                NaN        14.532354  \n0ab8c5be                NaN         6.993179  \n0d6b24b4                NaN        10.738063  \n12074250                NaN        19.813667  \n155f4f6a                NaN              NaN  \n\n[456 rows x 18 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_metric</th>\n      <th>time_this_iter_s</th>\n      <th>done</th>\n      <th>timesteps_total</th>\n      <th>episodes_total</th>\n      <th>training_iteration</th>\n      <th>experiment_id</th>\n      <th>date</th>\n      <th>timestamp</th>\n      <th>time_total_s</th>\n      <th>pid</th>\n      <th>hostname</th>\n      <th>node_ip</th>\n      <th>time_since_restore</th>\n      <th>timesteps_since_restore</th>\n      <th>iterations_since_restore</th>\n      <th>experiment_tag</th>\n      <th>config.init_std</th>\n    </tr>\n    <tr>\n      <th>trial_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>b4cbf1a6</th>\n      <td>0.53475</td>\n      <td>21.844446</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>dbcfb69484774346bc4230125d7b9053</td>\n      <td>2022-07-28_12-14-07</td>\n      <td>1.659003e+09</td>\n      <td>131.225310</td>\n      <td>18433.0</td>\n      <td>yaroslav-B365-M-AORUS-ELITE</td>\n      <td>217.105.36.71</td>\n      <td>131.225310</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>1_init_std=7.4971</td>\n      <td>7.497057</td>\n    </tr>\n    <tr>\n      <th>b4ebbf68</th>\n      <td>0.27135</td>\n      <td>33.228054</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>738ff7723b8a4ffea3966a4d1a3aefb2</td>\n      <td>2022-07-28_12-12-29</td>\n      <td>1.659003e+09</td>\n      <td>33.228054</td>\n      <td>18431.0</td>\n      <td>yaroslav-B365-M-AORUS-ELITE</td>\n      <td>217.105.36.71</td>\n      <td>33.228054</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2_init_std=19.015</td>\n      <td>19.014779</td>\n    </tr>\n    <tr>\n      <th>b500773c</th>\n      <td>0.41193</td>\n      <td>21.958321</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>a6033c902bfd4e7c973a3daf12877b67</td>\n      <td>2022-07-28_12-14-06</td>\n      <td>1.659003e+09</td>\n      <td>129.855627</td>\n      <td>18428.0</td>\n      <td>yaroslav-B365-M-AORUS-ELITE</td>\n      <td>217.105.36.71</td>\n      <td>129.855627</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>3_init_std=14.643</td>\n      <td>14.642559</td>\n    </tr>\n    <tr>\n      <th>b515478e</th>\n      <td>0.24309</td>\n      <td>34.450798</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>7db7aedf045045a9881286439d3fe2a7</td>\n      <td>2022-07-28_12-12-31</td>\n      <td>1.659003e+09</td>\n      <td>34.450798</td>\n      <td>18434.0</td>\n      <td>yaroslav-B365-M-AORUS-ELITE</td>\n      <td>217.105.36.71</td>\n      <td>34.450798</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4_init_std=11.977</td>\n      <td>11.977183</td>\n    </tr>\n    <tr>\n      <th>b530b35c</th>\n      <td>0.49560</td>\n      <td>21.790014</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>7afcfd67ed6841318941af1173e5194f</td>\n      <td>2022-07-28_12-14-08</td>\n      <td>1.659003e+09</td>\n      <td>131.416916</td>\n      <td>18429.0</td>\n      <td>yaroslav-B365-M-AORUS-ELITE</td>\n      <td>217.105.36.71</td>\n      <td>131.416916</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>5_init_std=3.1288</td>\n      <td>3.128813</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>0365c884</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1aca9fc1aee74e21aaee3b8ed30a635f</td>\n      <td>2022-07-28_13-11-37</td>\n      <td>1.659007e+09</td>\n      <td>NaN</td>\n      <td>32091.0</td>\n      <td>yaroslav-B365-M-AORUS-ELITE</td>\n      <td>217.105.36.71</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>14.532354</td>\n    </tr>\n    <tr>\n      <th>0ab8c5be</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9f62ef6ce760445d85e5d6e3710d196a</td>\n      <td>2022-07-28_13-11-41</td>\n      <td>1.659007e+09</td>\n      <td>NaN</td>\n      <td>32116.0</td>\n      <td>yaroslav-B365-M-AORUS-ELITE</td>\n      <td>217.105.36.71</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.993179</td>\n    </tr>\n    <tr>\n      <th>0d6b24b4</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9b830b62dc354d3fa50b0e2666f1b8b9</td>\n      <td>2022-07-28_13-11-49</td>\n      <td>1.659007e+09</td>\n      <td>NaN</td>\n      <td>32141.0</td>\n      <td>yaroslav-B365-M-AORUS-ELITE</td>\n      <td>217.105.36.71</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10.738063</td>\n    </tr>\n    <tr>\n      <th>12074250</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8c387cd02a244f5687474d4dc06c11aa</td>\n      <td>2022-07-28_13-11-54</td>\n      <td>1.659007e+09</td>\n      <td>NaN</td>\n      <td>32193.0</td>\n      <td>yaroslav-B365-M-AORUS-ELITE</td>\n      <td>217.105.36.71</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>19.813667</td>\n    </tr>\n    <tr>\n      <th>155f4f6a</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>456 rows Ã— 18 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_df = analysis.results_df\n",
    "analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "analysis_df.to_csv(\"result.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}